{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, os\n",
    "import pickle\n",
    "import cfgrib\n",
    "import pygrib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from glob import glob\n",
    "from datetime import datetime, timedelta\n",
    "from functools import partial, reduce\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model_config = 'clnx'\n",
    "site, interval, delay = 'CLNX', 12, 12\n",
    "site_lat, site_lon = 40.5763, -111.6383\n",
    "\n",
    "model = 'gfs0p25'\n",
    "\n",
    "temp = '/scratch/general/lustre/u1070830/binary_temp/'; os.makedirs(temp, exist_ok=True)\n",
    "archive = '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/archive/'\n",
    "\n",
    "obs_dir = '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/observations/clean/'\n",
    "\n",
    "date_fmt = '%Y%m%d'\n",
    "datetime_fmt = '%Y%m%d%H'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svr(X, config='all'):\n",
    "    \n",
    "    mlmodel_dir = '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/output/slr_models/%s/'%svr_model_config\n",
    "    \n",
    "    scaler_file = glob(mlmodel_dir + '*scaler*')[-1]#[-1]\n",
    "    stats_file = glob(mlmodel_dir + '*train_stats*')[-1]#[-1]\n",
    "    model_file = glob(mlmodel_dir + '*SLRmodel*')[-1]#[-1]\n",
    "    \n",
    "    with open(scaler_file, 'rb') as rfp:\n",
    "        scaler = pickle.load(rfp)\n",
    "\n",
    "    with open(stats_file, 'rb') as rfp:\n",
    "        train_stats, train_stats_norm = pickle.load(rfp)\n",
    "        model_keys = train_stats.keys()\n",
    "\n",
    "    with open(model_file, 'rb') as rfp:\n",
    "        SLRmodel = pickle.load(rfp)\n",
    "                        \n",
    "    X_trim = pd.DataFrame(X[model_keys]).T\n",
    "    \n",
    "    X_norm = pd.DataFrame(scaler.transform(X_trim), index=X_trim.index, columns=X_trim.keys())\n",
    "    \n",
    "    print(model_keys)\n",
    "    \n",
    "    return SLRmodel.predict(X_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio(X, units=None):\n",
    "    return 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nwstable(X, tvar='T2M', units='K'):\n",
    "    \n",
    "    x = X[tvar]\n",
    "    \n",
    "    x = x if units == 'C' else x-273.15\n",
    "    \n",
    "    if x > 1.5:\n",
    "        return 0\n",
    "    elif (-2.5 < x <= 1.5):\n",
    "        return 10\n",
    "    elif (-7.5 < x <= -2.5):\n",
    "        return 15\n",
    "    elif (-10 < x <= -7.5):\n",
    "        return 20\n",
    "    elif (-12.5 < x <= -10):\n",
    "        return 30\n",
    "    elif x <= -12.5:\n",
    "        return 40\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hrrr_asnow(X, tvar='T2M', units='K'):\n",
    "    \n",
    "    x = X[tvar]\n",
    "    \n",
    "    x = x if units == 'C' else x-273.15\n",
    "    return 100/np.min([250, 100. / np.max([4.179, (13.*np.tanh((274.15-(x+273.15))/3.))])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kuchera(X, tvar='T2M', units='K'):\n",
    "    \n",
    "    x = X[tvar]\n",
    "    \n",
    "    x = x if units == 'K' else x+273.15\n",
    "    \n",
    "    if x > 271.16:\n",
    "        return (12. + 2.*(271.16-x))\n",
    "    elif x <= 271.16:\n",
    "        return (12 + (271.16-x))\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_slr_only(X, wbzh=0, orog=0):\n",
    "    \n",
    "    tlayer = np.mean([X['T_400'], X['T_500'], X['T_600'], X['T_700'], X['T_800']])\n",
    "    \n",
    "    # Tunable transition layer parameters (m)\n",
    "    all_snow_buffer = 0\n",
    "    transition_layer = 200\n",
    "    \n",
    "    # Extend the snow level below the wet bulb zero parameter height if set\n",
    "    snow_level = wbzh - all_snow_buffer\n",
    "    snow_level = xr.where(snow_level < 0., 0., snow_level)\n",
    "\n",
    "    # Curve fit to Alcott and Steenburgh (2010) SMLR results\n",
    "    init_slr = xr.where(tlayer < 0., 5. - tlayer, 5.)\n",
    "    init_slr = xr.where(tlayer < -15., 20. + (tlayer + 15.), init_slr)\n",
    "    init_slr = xr.where(tlayer < -20., 15., init_slr)\n",
    "\n",
    "    # Keep the initial SLR calculations above the snow level\n",
    "    slr = xr.where(orog >= snow_level, init_slr, 0.)\n",
    "\n",
    "    # Linear attenuation of the SLR in the transition layer\n",
    "    slr = xr.where(\n",
    "        ((orog < snow_level) & (orog > (snow_level - transition_layer))),\n",
    "        (init_slr * (orog - (snow_level - transition_layer)) / transition_layer), slr)\n",
    "\n",
    "    return slr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_slr_complete():\n",
    "    return pd.DataFrame(xr.open_dataset('webslr.nc')['slr'].to_dataframe()['slr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alcott(X, exclude=None):\n",
    "    \n",
    "    predset = [\n",
    "        [X['T_650'], -3.31],\n",
    "        [X['SPD_600']**2, -1.73e-2],\n",
    "        [X['swe_mm'], 1.26],\n",
    "        [X['V_400'], 5.91e-2],\n",
    "        [(X['T_600'])**3, 3.33e-3],\n",
    "        [(X['T_800'])**3, 4.38e-3],\n",
    "        [1/(X['T_600']), -243],\n",
    "        [X['R_550'], 6.16e-6], \n",
    "        [((X['R_750'] + X['R_700'])/2), -0.136],\n",
    "        [X['R_850'], 6.91e-6],\n",
    "        [X['DIR_700'], 1.27e-2],\n",
    "        [abs(310.-X['DIR_700']), 1.76e-2], # Direction index, a deviation from 310\n",
    "        [(X['T_500'])**2, 6.47e-2],\n",
    "        [(X['T_500'])**3, 2.16e-3],\n",
    "        [(X['T_550'])**3, -2.11e-3], \n",
    "        [X['SPD_400'], -5.28e-2],\n",
    "        [X['SPD_600'], 0.342],\n",
    "    ]\n",
    "        \n",
    "    if exclude:\n",
    "        del predset[exclude]\n",
    "            \n",
    "    return np.sum([np.prod(i) for i in predset])-45\n",
    "\n",
    "def alcott_hiswe(X, exclude=None):\n",
    "    \n",
    "    predset = [\n",
    "        [(X['T_550']), -0.489],\n",
    "        [X['SPD_600']**2, -1.61e-2],\n",
    "        [((X['T_750'] + X['T_700'])/2), -0.936],\n",
    "        [X['V_650'], 0.215],\n",
    "        [X['T_400'], 0.396],\n",
    "        [1/(X['T_850']), -0.151],\n",
    "        [abs(310.-X['DIR_850']), -2.05e-2],  # Direction indeX, a deviation from 310\n",
    "        [X['R_450'], 1.02e-5], \n",
    "        [((X['R_850'] + X['R_800'])/2), -3.76e-6],]\n",
    "    \n",
    "    if exclude:\n",
    "        del predset[exclude]\n",
    "    \n",
    "    return np.sum([np.prod(i) for i in predset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_slr(model=None, zcorr=False, tcorr=False):\n",
    "    \n",
    "    modelname = str(model).split(' ')[1].upper()\n",
    "    modelname = 'HRRRv3 ASNOW \\n(No Graupel)' if 'hrrr' in modelname.lower() else modelname\n",
    "        \n",
    "    df = pd.read_pickle('./%s_%dh_delay%d_extract_gfs_ISO.pd'%(site, interval, delay))\n",
    "    \n",
    "    if zcorr:\n",
    "        df.loc[:, [k for k in df.keys() if 'Z_' in k]] *= 9.81\n",
    "    \n",
    "    if tcorr:\n",
    "        df.loc[:, [k for k in df.keys() if k[0] == 'T']] -= 273.15\n",
    "        \n",
    "    df.head()\n",
    "    \n",
    "    if modelname == 'WEB_SLR_COMPLETE':\n",
    "        slr = web_slr_complete()\n",
    "    \n",
    "    else:    \n",
    "        with mp.get_context('fork').Pool(128) as p:\n",
    "            returns = p.map(model, [v[1] for v in df.iterrows()])\n",
    "            p.close()\n",
    "            p.join()\n",
    "\n",
    "        slr = pd.DataFrame(returns,\n",
    "            index=df.index, columns=['slr'])\n",
    "        \n",
    "    slr[slr < 0] = 0\n",
    "    output = slr.merge(df['swe_mm'], on='time')\n",
    "    output['snow_mm'] = output['swe_mm'] * output['slr']\n",
    "\n",
    "    output = output.resample('12H', convention='end', label='right', closed='right').sum()[['swe_mm', 'snow_mm']]\n",
    "    output['slr_weighted'] = output['snow_mm']/output['swe_mm']\n",
    "    output.index = output.index.rename('valid')\n",
    "    \n",
    "    obs_file = glob(obs_dir + '%s*.pd'%site)[0]\n",
    "\n",
    "    obs = pd.read_pickle(obs_file).reset_index().rename(\n",
    "        columns={'datetime_utc':'valid'})#.set_index('valid')\n",
    "\n",
    "    # CONSIDER FIXING OFFSET IN INGEST (CLN SHOULD BE 04/16 MST 11/23 UTC)\n",
    "    obs['valid'] = obs['valid'] + timedelta(hours=3)\n",
    "    obs = obs.set_index('valid')\n",
    "\n",
    "    obs = obs[[k for k in obs.keys() if str(interval) in k]]\n",
    "    obs = obs.rename(columns={k:'obs_' + k.replace('%s'%interval, '') for k in obs.keys()})\n",
    "\n",
    "    swe_min = 2.54 #0.1 in \n",
    "    obs = obs[obs['obs_swe_mm'] >= 2.54]\n",
    "    \n",
    "    match = obs.merge(output, on='valid')\n",
    "    match = match.dropna(how='any')\n",
    "    \n",
    "    yt = match['obs_slr']\n",
    "    yp = match['slr_weighted']\n",
    "\n",
    "    # Bulk Statistics including: MAE, MAPE(MARE), MSE, RMSE, Bias Ratio\n",
    "    # Bottom line: R2 can be greater than 1.0 only when the chosen model (with constraints, if any)\n",
    "    # fits the data really poorly, worse than the fit of a horizontal line.\n",
    "    varexp = metrics.explained_variance_score(yt, yp)\n",
    "    r2 = metrics.r2_score(yt, yp) \n",
    "    mae = metrics.mean_absolute_error(yt, yp)\n",
    "    mse = metrics.mean_squared_error(yt, yp)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = mean_absolute_percentage_error(yt, yp)\n",
    "    mare = mape/100\n",
    "    statstr = 'R$^2$ {:.2f}\\nMAE {:.2f}\\nMSE {:.2f}\\nRMSE {:.2f}\\nMARE {:.2f}'.format(r2, mae, mse, rmse, mare)\n",
    "    print(statstr.replace('\\n', ' | '))\n",
    "    \n",
    "    fig, ax = plt.subplots(1, figsize=(12, 12), facecolor='w')\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "    ax.scatter(yp, yt, marker='+', s=150, c='k', linewidth=0.75, label='%s SLR'%modelname)\n",
    "\n",
    "    max_slr = max(max(yt), max(yp))\n",
    "    max_slr = np.ceil(max_slr/10)*10\n",
    "    ax.plot(np.arange(max_slr+1), '--', label='Perfect Forecast')\n",
    "\n",
    "    ax.set_xlim([0, max_slr])\n",
    "    ax.set_ylim([0, max_slr])\n",
    "    ax.set_xlabel('Forecast SLR (CLN)')\n",
    "    ax.set_ylabel('Observed SLR (%s)'%site.upper())\n",
    "    ax.set_title('%s Direct Time Match - 12h Resampled\\nn=%d'%(modelname, len(yp)))\n",
    "\n",
    "    ax.legend(loc='upper right', edgecolor='k')\n",
    "    ax.text(1, max_slr-1.5, 'High Bias')\n",
    "    ax.text(max_slr-7, 2, 'Low Bias')\n",
    "\n",
    "    ax.text(32, 27, statstr)\n",
    "\n",
    "    ax.grid()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    # savestr = '%s_bulkstats'%modelname\n",
    "    # plt.savefig('./figures/'+savestr+'.resampled.png', dpi=180)\n",
    "    # plt.show()\n",
    "    \n",
    "    return slr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returned = verify_slr(svr, zcorr=True, tcorr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returned = verify_slr(alcott, zcorr=False, tcorr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returned = verify_slr(web_slr_complete, zcorr=False, tcorr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returned = verify_slr(hrrr_asnow, zcorr=True, tcorr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returned = verify_slr(kuchera, zcorr=True, tcorr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
