{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "from os.path import isfile\n",
    "from functools import partial\n",
    "from subprocess import Popen, call\n",
    "from multiprocessing import get_context\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = '/uufs/chpc.utah.edu/common/home/u1070830/code/snow-liquid-ratio/'\n",
    "era5_script_dir = '/uufs/chpc.utah.edu/common/home/u1070830/code/model-tools/era5/'\n",
    "obs_path = '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/observations/'\n",
    "era5_path = '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/era5/'\n",
    "gfs_path = '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/gfs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with the metadata file as an efficent way to keep data organized vs a config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_excel(obs_path + 'Dataset_Metadata.xlsx').set_index('code')\n",
    "metadata.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over each station:\n",
    "We don't want to re-run on data already processed, so check each step first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ensure the observation data exists and is read in to .pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_list = metadata.index.values.astype('str')\n",
    "print('Sites to process:', site_list)\n",
    "\n",
    "ingest_script = script_dir + 'data-tools/generic_data_ingest.py'\n",
    "\n",
    "for site in site_list:\n",
    "    \n",
    "    if len(glob(obs_path + 'clean/%s_*.pd'%site)) > 0:\n",
    "        print('File exists, skipping: %s'%site)\n",
    "    else:\n",
    "        try:\n",
    "            run_cmd = ('python ' + ingest_script + ' %s'%site)\n",
    "            call(run_cmd, shell=True)\n",
    "\n",
    "        except:\n",
    "            print('Ingest %s failed to run'%site)\n",
    "            # raise\n",
    "\n",
    "        else:\n",
    "            # Check to see if file was written before declaring success - \n",
    "            # call won't catch failures in the child script\n",
    "            \n",
    "            if len(glob(obs_path + 'clean/%s_*.pd'%site)) > 0:\n",
    "                print('Ingest %s success'%site)\n",
    "                \n",
    "            else:\n",
    "                print('Ingest %s failed to write'%site)\n",
    "                # raise\n",
    "                \n",
    "                # Fail cases (log these within child script:\n",
    "                #     No header info for site/file\n",
    "                #     No file found for site\n",
    "                #     Header mismatch/read error\n",
    "                #     Data mismatch error (automated - manual too large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ensure the era5 profile has been created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for site in site_list:\n",
    "def profiles(site, metadata):\n",
    "\n",
    "    site_lat, site_lon = metadata.loc[site, ['lat', 'lon']].values\n",
    "    \n",
    "    # We need to first determine the output filename (All ERA5 profiles are xx.xxN, xxx.xxW)\n",
    "    sample = xr.open_dataset(era5_script_dir + 'era5_sample.nc')\n",
    "    a = abs(sample['latitude']-site_lat)+abs(sample['longitude']-360-site_lon)\n",
    "    yi, xi = np.unravel_index(a.argmin(), a.shape)\n",
    "\n",
    "    lat = sample.isel(latitude=yi, longitude=xi)['latitude']\n",
    "    lon = sample.isel(latitude=yi, longitude=xi)['longitude'] - 360\n",
    "    \n",
    "    era5_prof_file = 'era5prof_%.2fN_%.2fW.nc'%(lat, abs(lon))\n",
    "\n",
    "    print('\\nSite: %s %.3f %.3f\\n%s\\n'%(site, site_lat, site_lon, era5_prof_file))\n",
    "    \n",
    "    iter_count = 0\n",
    "    while not isfile(era5_path + '/profiles/' + era5_prof_file):\n",
    "        iter_count += 1\n",
    "        \n",
    "        run_cmd = era5_script_dir + 'extract_agg_profile.sh %.2f %.2f 1980 2020'%(lat, lon)\n",
    "        P = Popen(run_cmd, shell=True, stdout=PIPE, stderr=PIPE)\n",
    "        output, err = P.communicate()\n",
    "\n",
    "    print('%s Complete'%era5_prof_file)\n",
    "\n",
    "# 10 process workers seems OK for now...\n",
    "worker_cap = 10\n",
    "n_workers = len(site_list) if len(site_list) < worker_cap else worker_cap\n",
    "\n",
    "profiles_mp = partial(profiles, metadata=metadata)\n",
    "with get_context('fork').Pool(10) as p:\n",
    "    p.map(profiles_mp, site_list)\n",
    "    p.close()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pair the observations and ERA5 profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass cases:\n",
    "#     Produced new site pair\n",
    "#     Site pair found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extract a GFS profile for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass cases:\n",
    "#     Produced new GFS profile\n",
    "#     GFS profile found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data Pre-Processing Completed...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
