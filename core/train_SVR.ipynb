{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "obdir = '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/observations/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose which sites to train the SVR model on\n",
    "Can be all available, or a defined list 'site_list' passed, or single station as list e.g. ['CLN']<br>\n",
    "Use all with an exclude list is another alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AGD', 'ALTA', 'BCC', 'BSNFDC', 'BSNFEX', 'BSNFJE', 'CLNX', 'PVC',\n",
       "       'SLB'], dtype='<U6')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flist = glob(obdir + 'combined/*.pd')\n",
    "\n",
    "# This can be a manual site list if desired\n",
    "site_list = np.unique([f.split('/')[-1].split('_')[0] for f in flist])\n",
    "\n",
    "# site_list = [s for s in site_list if 'BSNF' in s]\n",
    "# site_list = ['CLN', 'AGD', 'ALTA']\n",
    "\n",
    "site_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each site, choose which files to use\n",
    "For now, we will only use one set of observations from each site so samples remain independent<br>\n",
    "We can change this behavior down the road to use all or some intervals<br>\n",
    "Favor 'short' for the shortest interval available e.g. 6h, 'long' for longest interval e.g. 24h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/observations/combined/AGD_2004_2019.24h.pd',\n",
       "       '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/observations/combined/AGD_2004_2019.12h.pd',\n",
       "       '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/observations/combined/ALTA_1980_2020.24h.pd',\n",
       "       '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/observations/combined/BCC_2004_2019.24h.pd',\n",
       "       '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/observations/combined/BCC_2004_2019.12h.pd',\n",
       "       '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/observations/combined/BSNFDC_2005_2019.24h.pd',\n",
       "       '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/observations/combined/BSNFEX_2012_2019.24h.pd',\n",
       "       '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/observations/combined/BSNFJE_2005_2019.24h.pd',\n",
       "       '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/observations/combined/CLNX_1999_2019.24h.pd',\n",
       "       '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/observations/combined/CLNX_1999_2019.12h.pd',\n",
       "       '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/observations/combined/PVC_2006_2019.24h.pd',\n",
       "       '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/observations/combined/PVC_2006_2019.12h.pd',\n",
       "       '/uufs/chpc.utah.edu/common/home/steenburgh-group10/mewessler/observations/combined/SLB_1980_2020.24h.pd'],\n",
       "      dtype='<U106')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# favor = 'long' #'long'\n",
    "\n",
    "flist = []\n",
    "for site in site_list:\n",
    "    \n",
    "    site_files = glob(obdir + 'combined/%s*.pd'%site)\n",
    "    \n",
    "#     if len(site_files) > 1:\n",
    "#         if favor == 'short':\n",
    "#             flist.append(\n",
    "#                 site_files[np.argmin([int(f.split('.')[-2].replace('h', '')) \n",
    "#                     for f in site_files])])\n",
    "            \n",
    "#         elif favor == 'long':\n",
    "#             np.argmax([int(f.split('.')[-2].replace('h', '')) for f in site_files])\n",
    "    \n",
    "#     else:\n",
    "    flist.append(site_files)#[0])\n",
    "        \n",
    "flist = np.hstack(flist)\n",
    "flist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish which model variables and levels to use\n",
    "This is entirely based on the model that the SVR will be applied to - maximize the predictor set<br>\n",
    "Helpful to open a sample GFS/NAM/HRRR grid or profile to derive the variable list from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the compiled data\n",
    "Prune unused variables on import based on the list above<br>\n",
    "Sub-surface levels have already been dealt with in the compilation script - modify methods there<br>\n",
    "Note that 12 vs 24 hour intervals have also been dealt with above, if both desired... write that in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14340, 106)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slr</th>\n",
       "      <th>swe_mm</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>Q_01agl</th>\n",
       "      <th>T_01agl</th>\n",
       "      <th>U_01agl</th>\n",
       "      <th>V_01agl</th>\n",
       "      <th>VO_01agl</th>\n",
       "      <th>W_01agl</th>\n",
       "      <th>Z_01agl</th>\n",
       "      <th>...</th>\n",
       "      <th>CAPE</th>\n",
       "      <th>MSL</th>\n",
       "      <th>U10M</th>\n",
       "      <th>V10M</th>\n",
       "      <th>U100M</th>\n",
       "      <th>V100M</th>\n",
       "      <th>SPD10M</th>\n",
       "      <th>DIR10M</th>\n",
       "      <th>SPD100M</th>\n",
       "      <th>DIR100M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.88</td>\n",
       "      <td>12.95</td>\n",
       "      <td>314</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>274.660889</td>\n",
       "      <td>-7.088934</td>\n",
       "      <td>10.160769</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>0.417323</td>\n",
       "      <td>30329.960938</td>\n",
       "      <td>...</td>\n",
       "      <td>16.625</td>\n",
       "      <td>101563.398438</td>\n",
       "      <td>-1.797048</td>\n",
       "      <td>0.601576</td>\n",
       "      <td>-2.510218</td>\n",
       "      <td>1.441005</td>\n",
       "      <td>1.971800</td>\n",
       "      <td>108.770012</td>\n",
       "      <td>3.074048</td>\n",
       "      <td>122.917458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.32</td>\n",
       "      <td>11.94</td>\n",
       "      <td>329</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>264.753296</td>\n",
       "      <td>4.310259</td>\n",
       "      <td>-6.581493</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>-0.061324</td>\n",
       "      <td>29981.410156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245</td>\n",
       "      <td>102496.562500</td>\n",
       "      <td>0.190780</td>\n",
       "      <td>0.362110</td>\n",
       "      <td>0.818864</td>\n",
       "      <td>0.244969</td>\n",
       "      <td>1.172219</td>\n",
       "      <td>187.995560</td>\n",
       "      <td>1.427766</td>\n",
       "      <td>243.507050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.21</td>\n",
       "      <td>21.84</td>\n",
       "      <td>330</td>\n",
       "      <td>0.003708</td>\n",
       "      <td>269.180389</td>\n",
       "      <td>8.406146</td>\n",
       "      <td>-2.683464</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>-0.380196</td>\n",
       "      <td>30030.525391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785</td>\n",
       "      <td>101940.070312</td>\n",
       "      <td>-0.430602</td>\n",
       "      <td>1.840145</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>3.492149</td>\n",
       "      <td>2.040003</td>\n",
       "      <td>168.747421</td>\n",
       "      <td>3.617625</td>\n",
       "      <td>182.818176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.20</td>\n",
       "      <td>25.40</td>\n",
       "      <td>331</td>\n",
       "      <td>0.003646</td>\n",
       "      <td>269.066162</td>\n",
       "      <td>8.432843</td>\n",
       "      <td>-0.374978</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>-0.620179</td>\n",
       "      <td>29730.644531</td>\n",
       "      <td>...</td>\n",
       "      <td>3.590</td>\n",
       "      <td>101485.796875</td>\n",
       "      <td>0.227602</td>\n",
       "      <td>1.250961</td>\n",
       "      <td>0.800089</td>\n",
       "      <td>2.296890</td>\n",
       "      <td>1.909311</td>\n",
       "      <td>204.083237</td>\n",
       "      <td>3.194682</td>\n",
       "      <td>213.687454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.34</td>\n",
       "      <td>13.21</td>\n",
       "      <td>332</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>263.492554</td>\n",
       "      <td>7.508132</td>\n",
       "      <td>-4.722282</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-0.302856</td>\n",
       "      <td>29630.097656</td>\n",
       "      <td>...</td>\n",
       "      <td>31.320</td>\n",
       "      <td>101991.617188</td>\n",
       "      <td>0.491865</td>\n",
       "      <td>-0.699195</td>\n",
       "      <td>1.275965</td>\n",
       "      <td>-1.004299</td>\n",
       "      <td>1.864576</td>\n",
       "      <td>234.394958</td>\n",
       "      <td>2.894353</td>\n",
       "      <td>251.885300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     slr  swe_mm  day_of_year   Q_01agl     T_01agl   U_01agl    V_01agl  \\\n",
       "0   5.88   12.95          314  0.004574  274.660889 -7.088934  10.160769   \n",
       "1   5.32   11.94          329  0.002019  264.753296  4.310259  -6.581493   \n",
       "2  12.21   21.84          330  0.003708  269.180389  8.406146  -2.683464   \n",
       "3  12.20   25.40          331  0.003646  269.066162  8.432843  -0.374978   \n",
       "4  16.34   13.21          332  0.001820  263.492554  7.508132  -4.722282   \n",
       "\n",
       "   VO_01agl   W_01agl       Z_01agl  ...    CAPE            MSL      U10M  \\\n",
       "0 -0.000104  0.417323  30329.960938  ...  16.625  101563.398438 -1.797048   \n",
       "1  0.000111 -0.061324  29981.410156  ...   0.245  102496.562500  0.190780   \n",
       "2  0.000110 -0.380196  30030.525391  ...   0.785  101940.070312 -0.430602   \n",
       "3  0.000093 -0.620179  29730.644531  ...   3.590  101485.796875  0.227602   \n",
       "4  0.000030 -0.302856  29630.097656  ...  31.320  101991.617188  0.491865   \n",
       "\n",
       "       V10M     U100M     V100M    SPD10M      DIR10M   SPD100M     DIR100M  \n",
       "0  0.601576 -2.510218  1.441005  1.971800  108.770012  3.074048  122.917458  \n",
       "1  0.362110  0.818864  0.244969  1.172219  187.995560  1.427766  243.507050  \n",
       "2  1.840145  0.024700  3.492149  2.040003  168.747421  3.617625  182.818176  \n",
       "3  1.250961  0.800089  2.296890  1.909311  204.083237  3.194682  213.687454  \n",
       "4 -0.699195  1.275965 -1.004299  1.864576  234.394958  2.894353  251.885300  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_var_type = ['mean']#, 'max', 'min']\n",
    "\n",
    "data = []\n",
    "for f in flist:\n",
    "    \n",
    "    site = f.split('/')[-1].split('_')[0]\n",
    "    interval = int(f.split('/')[-1].split('.')[-2].replace('h', ''))\n",
    "    \n",
    "    df = pd.read_pickle(f)\n",
    "    \n",
    "    exclude_keys = ['VO', 'Z', 'W'] #['Z', '2T', 'TSFC', 'CAPE', 'VO', 'W', 'V', 'U']\n",
    "    exclude_keys = np.array([[k if ex in k[:len(ex)] else np.nan \n",
    "                              for ex in exclude_keys] for k in df.keys()])\n",
    "    exclude_keys = exclude_keys.flatten()\n",
    "    exclude_keys = exclude_keys[exclude_keys != 'nan']\n",
    "    \n",
    "    keys = ['slr', 'swe_mm']\n",
    "\n",
    "    keys.extend(np.hstack([[k for k in df.keys() if vt in k] for vt in use_var_type]))\n",
    "\n",
    "    df = df.loc[:, keys].rename(columns={[k for k in keys if 'swe' in k][0]:'swe_mm'})\n",
    "    df = df.loc[:, :].rename(columns={[k for k in keys if 'swe' in k][0]:'swe_mm'})\n",
    "    df = df.rename(columns={[k for k in keys if 'slr' in k][0]:'slr'})\n",
    "    df = df.drop(columns=[k for k in keys if 'auto' in k])\n",
    "    \n",
    "    # df.insert(0, 'site', np.full(df.index.size, fill_value=site, dtype='U10'))\n",
    "    doy = [int(pd.to_datetime(d).strftime('%j')) for d in df.index]\n",
    "    df.insert(2, 'day_of_year', doy)\n",
    "    \n",
    "    data.append(df.reset_index().drop(columns='time'))\n",
    "\n",
    "data = pd.concat(data, sort=False)\n",
    "\n",
    "# Treat the mean value as the instantaneous value for later applications,\n",
    "# we can change this behavior later on if desired. \n",
    "# An alternate method would be to keep the 'mean' tag through training \n",
    "# and choose behavior upon application\n",
    "data = data.rename(columns={k:k.replace('_mean', '') for k in data.keys()})\n",
    "\n",
    "data = data.drop(columns='SP')\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard trim data based on criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10795, 106)\n"
     ]
    }
   ],
   "source": [
    "min_slr, max_slr = 2.5, 30\n",
    "max_T650 = 0 + 273.15\n",
    "min_swe_mm = 2.54\n",
    "\n",
    "data = data[data['slr'] >= min_slr]\n",
    "data = data[data['slr'] <= max_slr]\n",
    "data = data[data['T_01agl'] <= max_T650]\n",
    "data = data[data['swe_mm'] >= min_swe_mm]\n",
    "\n",
    "# data = data[[k for k in data.keys() if 'swe' not in k]]\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(facecolor='w', figsize=(6, 6))\n",
    "data['slr'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate basic bulk statistics and linear correlations\n",
    "Quanitfy how certain variables are related and produce plots to visualize this<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Removed: Normalize/Standardize\n",
    "Moved down to where datasets are split. If need be we can normalize for the plots below here too..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pair Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Matrix, R2 Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Correlation Verical Plots, R2 Vertical Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify autocorrelated and other dependent predictors\n",
    "Mask these if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train/Test/Validate Sets\n",
    "If we want to expand the hyperparameter tuning, we can test for sensitivity to random sample<br>\n",
    "by looping from bottom of code block back to here<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0    4001\n",
       "15.0    3132\n",
       "20.0    1741\n",
       "5.0     1183\n",
       "25.0     588\n",
       "30.0     150\n",
       "Name: slr, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# int(slr) for stratification (> 1 ct per class label)\n",
    "data = data.dropna()\n",
    "fac = 5\n",
    "slr = np.round(data['slr']/fac, 0)*fac\n",
    "slr.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 10795\n",
      "Train: 7232\n",
      "Test: 3563\n",
      "Validate: None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>swe_mm</th>\n",
       "      <td>7232.0</td>\n",
       "      <td>14.247430</td>\n",
       "      <td>11.198167</td>\n",
       "      <td>2.540000</td>\n",
       "      <td>6.350000</td>\n",
       "      <td>10.920000</td>\n",
       "      <td>18.540001</td>\n",
       "      <td>104.139999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_of_year</th>\n",
       "      <td>7232.0</td>\n",
       "      <td>151.441095</td>\n",
       "      <td>135.598582</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>366.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q_01agl</th>\n",
       "      <td>7232.0</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.005285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T_01agl</th>\n",
       "      <td>7232.0</td>\n",
       "      <td>266.811981</td>\n",
       "      <td>3.933001</td>\n",
       "      <td>245.684555</td>\n",
       "      <td>264.360870</td>\n",
       "      <td>267.250748</td>\n",
       "      <td>269.791496</td>\n",
       "      <td>273.149200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U_01agl</th>\n",
       "      <td>7232.0</td>\n",
       "      <td>4.979368</td>\n",
       "      <td>3.655672</td>\n",
       "      <td>-10.994852</td>\n",
       "      <td>2.314884</td>\n",
       "      <td>5.038821</td>\n",
       "      <td>7.468368</td>\n",
       "      <td>19.270977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V_01agl</th>\n",
       "      <td>7232.0</td>\n",
       "      <td>2.281828</td>\n",
       "      <td>5.773494</td>\n",
       "      <td>-14.995266</td>\n",
       "      <td>-1.535056</td>\n",
       "      <td>1.626354</td>\n",
       "      <td>6.392091</td>\n",
       "      <td>23.066927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VO_01agl</th>\n",
       "      <td>7232.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W_01agl</th>\n",
       "      <td>7232.0</td>\n",
       "      <td>-0.291711</td>\n",
       "      <td>0.417225</td>\n",
       "      <td>-2.432395</td>\n",
       "      <td>-0.522965</td>\n",
       "      <td>-0.234067</td>\n",
       "      <td>-0.011146</td>\n",
       "      <td>1.088750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z_01agl</th>\n",
       "      <td>7232.0</td>\n",
       "      <td>27635.001953</td>\n",
       "      <td>3994.812256</td>\n",
       "      <td>12350.642578</td>\n",
       "      <td>28549.563477</td>\n",
       "      <td>29217.599609</td>\n",
       "      <td>29648.210449</td>\n",
       "      <td>30829.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_01agl</th>\n",
       "      <td>7232.0</td>\n",
       "      <td>76.924622</td>\n",
       "      <td>17.570309</td>\n",
       "      <td>4.356611</td>\n",
       "      <td>67.330038</td>\n",
       "      <td>81.159668</td>\n",
       "      <td>90.402494</td>\n",
       "      <td>102.348175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count          mean          std           min           25%  \\\n",
       "swe_mm       7232.0     14.247430    11.198167      2.540000      6.350000   \n",
       "day_of_year  7232.0    151.441095   135.598582      1.000000     43.000000   \n",
       "Q_01agl      7232.0      0.002488     0.000833      0.000231      0.001904   \n",
       "T_01agl      7232.0    266.811981     3.933001    245.684555    264.360870   \n",
       "U_01agl      7232.0      4.979368     3.655672    -10.994852      2.314884   \n",
       "V_01agl      7232.0      2.281828     5.773494    -14.995266     -1.535056   \n",
       "VO_01agl     7232.0      0.000006     0.000081     -0.000535     -0.000026   \n",
       "W_01agl      7232.0     -0.291711     0.417225     -2.432395     -0.522965   \n",
       "Z_01agl      7232.0  27635.001953  3994.812256  12350.642578  28549.563477   \n",
       "R_01agl      7232.0     76.924622    17.570309      4.356611     67.330038   \n",
       "\n",
       "                      50%           75%           max  \n",
       "swe_mm          10.920000     18.540001    104.139999  \n",
       "day_of_year     86.000000    324.000000    366.000000  \n",
       "Q_01agl          0.002465      0.003057      0.005285  \n",
       "T_01agl        267.250748    269.791496    273.149200  \n",
       "U_01agl          5.038821      7.468368     19.270977  \n",
       "V_01agl          1.626354      6.392091     23.066927  \n",
       "VO_01agl         0.000011      0.000054      0.000303  \n",
       "W_01agl         -0.234067     -0.011146      1.088750  \n",
       "Z_01agl      29217.599609  29648.210449  30829.937500  \n",
       "R_01agl         81.159668     90.402494    102.348175  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Total: %d'%len(data))\n",
    "\n",
    "# Split into train/test sets\n",
    "train_size, test_size, random_state = None, 0.33, 5\n",
    "X_train, X_test = train_test_split(data, \n",
    "                                       test_size=test_size, train_size=train_size, \n",
    "                                       random_state=random_state, stratify=slr)\n",
    "\n",
    "# Perform a secondary split if separate validation set required\n",
    "\n",
    "# Split off the target variable now that TTsplit is done\n",
    "y_train, y_test = X_train.pop('slr'), X_test.pop('slr')\n",
    "# y_train = np.round(y_train/fac, 0)*fac\n",
    "\n",
    "print('Train: {}\\nTest: {}\\nValidate: {}'.format(X_train.shape[0], X_test.shape[0], None))\n",
    "\n",
    "train_stats = X_train.describe().T\n",
    "train_stats.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize/Standardize the data\n",
    "We are using z-score normalization for now but other methods exist<br>\n",
    "This is an absolute must for working with any of the ML models available to us<br>\n",
    "Normalize based on the TRAINING dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>swe_mm</th>\n",
       "      <td>7232.0</td>\n",
       "      <td>0.272964</td>\n",
       "      <td>0.918635</td>\n",
       "      <td>-0.687449</td>\n",
       "      <td>-0.374897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625103</td>\n",
       "      <td>7.647251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_of_year</th>\n",
       "      <td>7232.0</td>\n",
       "      <td>0.232886</td>\n",
       "      <td>0.482557</td>\n",
       "      <td>-0.302491</td>\n",
       "      <td>-0.153025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.846975</td>\n",
       "      <td>0.996441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q_01agl</th>\n",
       "      <td>7232.0</td>\n",
       "      <td>0.020362</td>\n",
       "      <td>0.722300</td>\n",
       "      <td>-1.937657</td>\n",
       "      <td>-0.486200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.513800</td>\n",
       "      <td>2.445879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T_01agl</th>\n",
       "      <td>7232.0</td>\n",
       "      <td>-0.080796</td>\n",
       "      <td>0.724226</td>\n",
       "      <td>-3.971217</td>\n",
       "      <td>-0.532144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.467856</td>\n",
       "      <td>1.086146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U_01agl</th>\n",
       "      <td>7232.0</td>\n",
       "      <td>-0.011536</td>\n",
       "      <td>0.709359</td>\n",
       "      <td>-3.111230</td>\n",
       "      <td>-0.528562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471438</td>\n",
       "      <td>2.761657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V_01agl</th>\n",
       "      <td>7232.0</td>\n",
       "      <td>0.082687</td>\n",
       "      <td>0.728319</td>\n",
       "      <td>-2.096797</td>\n",
       "      <td>-0.398808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.601192</td>\n",
       "      <td>2.704702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VO_01agl</th>\n",
       "      <td>7232.0</td>\n",
       "      <td>-0.065399</td>\n",
       "      <td>1.006285</td>\n",
       "      <td>-6.821649</td>\n",
       "      <td>-0.460943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.539057</td>\n",
       "      <td>3.641527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W_01agl</th>\n",
       "      <td>7232.0</td>\n",
       "      <td>-0.112627</td>\n",
       "      <td>0.815181</td>\n",
       "      <td>-4.295127</td>\n",
       "      <td>-0.564455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.435545</td>\n",
       "      <td>2.584541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z_01agl</th>\n",
       "      <td>7232.0</td>\n",
       "      <td>-1.440498</td>\n",
       "      <td>3.636120</td>\n",
       "      <td>-15.352481</td>\n",
       "      <td>-0.608053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391947</td>\n",
       "      <td>1.467567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_01agl</th>\n",
       "      <td>7232.0</td>\n",
       "      <td>-0.183554</td>\n",
       "      <td>0.761527</td>\n",
       "      <td>-3.328777</td>\n",
       "      <td>-0.599400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400600</td>\n",
       "      <td>0.918346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count      mean       std        min       25%  50%       75%  \\\n",
       "swe_mm       7232.0  0.272964  0.918635  -0.687449 -0.374897  0.0  0.625103   \n",
       "day_of_year  7232.0  0.232886  0.482557  -0.302491 -0.153025  0.0  0.846975   \n",
       "Q_01agl      7232.0  0.020362  0.722300  -1.937657 -0.486200  0.0  0.513800   \n",
       "T_01agl      7232.0 -0.080796  0.724226  -3.971217 -0.532144  0.0  0.467856   \n",
       "U_01agl      7232.0 -0.011536  0.709359  -3.111230 -0.528562  0.0  0.471438   \n",
       "V_01agl      7232.0  0.082687  0.728319  -2.096797 -0.398808  0.0  0.601192   \n",
       "VO_01agl     7232.0 -0.065399  1.006285  -6.821649 -0.460943  0.0  0.539057   \n",
       "W_01agl      7232.0 -0.112627  0.815181  -4.295127 -0.564455  0.0  0.435545   \n",
       "Z_01agl      7232.0 -1.440498  3.636120 -15.352481 -0.608053  0.0  0.391947   \n",
       "R_01agl      7232.0 -0.183554  0.761527  -3.328777 -0.599400  0.0  0.400600   \n",
       "\n",
       "                  max  \n",
       "swe_mm       7.647251  \n",
       "day_of_year  0.996441  \n",
       "Q_01agl      2.445879  \n",
       "T_01agl      1.086146  \n",
       "U_01agl      2.761657  \n",
       "V_01agl      2.704702  \n",
       "VO_01agl     3.641527  \n",
       "W_01agl      2.584541  \n",
       "Z_01agl      1.467567  \n",
       "R_01agl      0.918346  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = RobustScaler(quantile_range=(25, 75)).fit(X_train)\n",
    "\n",
    "X_train_norm = pd.DataFrame(scaler.transform(X_train.loc[:, list(X_train.keys())]), columns=X_train.keys())\n",
    "X_test_norm = pd.DataFrame(scaler.transform(X_test.loc[:, list(X_train.keys())]), columns=X_train.keys())\n",
    "\n",
    "X_train_norm.describe().T.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out plots describing the variability in the data (+ before/after normalization?)<br>\n",
    "It would be valuable to do a similar set of/novel comparison plots with the ERA5 vs GFS<br>\n",
    "for each variable/level in the validation script (separate from and following this script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EOF/PCA Reduction of highly dimensional data\n",
    "There are implementations of atmospheric data in ML models that heavily leverage<br>\n",
    "EOFs to reduce highly dimensional data to simpler components<br>\n",
    "Evaluate if this is viable here as it will be applied to raw variables later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use LASSO/Ridge regression to determine predictor rank/impact\n",
    "L1/L2 Parameter Tuning -- Use to select relevant predictors, reduce irrelevant to zero, rank by influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# lr = LinearRegression()\n",
    "# lr.fit(X_train_norm, y_train)\n",
    "\n",
    "# lr_train_score = lr.score(X_train_norm, y_train)\n",
    "# lr_test_score = lr.score(X_test_norm, y_test)\n",
    "\n",
    "# print('Linear Regression Train Score: %.3f'%lr_train_score)\n",
    "# print('Linear Regression Test Score: %.3f'%lr_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, facecolor='w', figsize=(8, 14))\n",
    "\n",
    "# ranksort = np.argsort(abs(lr.coef_))[::-1]\n",
    "# lr_coefs = lr.coef_[ranksort]\n",
    "# lr_keys = X_train_norm.keys()[ranksort]\n",
    "# mask = lr_coefs != 0\n",
    "\n",
    "# ax.axvline(0, color='k', linewidth=3, zorder=11)\n",
    "# ax.barh(lr_keys[mask], lr_coefs[mask], color='green', zorder=10, height=0.97)\n",
    "\n",
    "# for i, k in enumerate(lr_keys[mask]):\n",
    "#     if lr_coefs[i] != 0:\n",
    "#         ax.text(lr_coefs[i]/2, k, k, zorder=20)\n",
    "\n",
    "# ax.invert_yaxis()\n",
    "# ax.axes.get_yaxis().set_visible(False)\n",
    "# ax.set_title('Linear Regression Coefs')\n",
    "# ax.set_xlabel('Linear Coef Value')\n",
    "# ax.grid(zorder=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import Ridge\n",
    "\n",
    "# # The higher the alpha value, more restriction on the coefficients; \n",
    "# # low alpha > more generalization, coefficients are barely restricted\n",
    "# rr_alpha_tune = []\n",
    "# for alpha in np.append(np.arange(0.01, 1, 0.01), np.arange(1, 1000, 1)):\n",
    "\n",
    "#     rr = Ridge(alpha=alpha)\n",
    "#     rr.fit(X_train, y_train)\n",
    "\n",
    "#     rr_train_score = rr.score(X_train, y_train)\n",
    "#     rr_test_score = rr.score(X_test, y_test)\n",
    "    \n",
    "#     rr_alpha_tune.append([alpha, rr_train_score, rr_test_score, rr])\n",
    "# rr_alpha_tune = np.array(rr_alpha_tune)\n",
    "\n",
    "# alpha, rr_train_score, rr_test_score, rr = rr_alpha_tune[np.argmax(rr_alpha_tune[:, 2])]\n",
    "# print('Ridge Regression alpha: %.3f'%alpha)\n",
    "# print('Ridge Regression Train Score: %.3f'%rr_train_score)\n",
    "# print('Ridge Regression Test Score: %.3f'%rr_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, facecolor='w', figsize=(8, 14))\n",
    "\n",
    "# ranksort = np.argsort(abs(rr.coef_))[::-1]\n",
    "# rr_coefs = rr.coef_[ranksort]\n",
    "# rr_keys = X_train_norm.keys()[ranksort]\n",
    "# mask = rr_coefs != 0\n",
    "\n",
    "# ax.axvline(0, color='k', linewidth=3, zorder=11)\n",
    "# ax.barh(rr_keys[mask], rr_coefs[mask], color='green', zorder=10, height=0.97)\n",
    "\n",
    "# for i, k in enumerate(rr_keys[mask]):\n",
    "#     if rr_coefs[i] != 0:\n",
    "#         ax.text(rr_coefs[i]/2, k, k, zorder=20)\n",
    "\n",
    "# ax.invert_yaxis()\n",
    "# ax.axes.get_yaxis().set_visible(False)\n",
    "# ax.set_title('Ridge Regression Coefs')\n",
    "# ax.set_xlabel('Ridge Coef Value')\n",
    "# ax.grid(zorder=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import Lasso\n",
    "\n",
    "# lasso_alpha_tune = []\n",
    "# for alpha in np.arange(0.001, .01, 0.001):\n",
    "\n",
    "#     lasso = Lasso(alpha=alpha, max_iter=10e5)\n",
    "#     lasso.fit(X_train_norm, y_train)\n",
    "\n",
    "#     lasso_train_score = lasso.score(X_train_norm, y_train)\n",
    "#     lasso_test_score = lasso.score(X_test_norm, y_test)\n",
    "#     lasso_coeff_used = np.sum(lasso.coef_ != 0)\n",
    "    \n",
    "#     lasso_alpha_tune.append([alpha, lasso_train_score, lasso_test_score, lasso])\n",
    "# lasso_alpha_tune = np.array(lasso_alpha_tune)\n",
    "\n",
    "# alpha, lasso_train_score, lasso_test_score, lasso = lasso_alpha_tune[np.argmax(lasso_alpha_tune[:, 2])]\n",
    "# print('Lasso alpha: %.3f'%alpha)\n",
    "# print('Lasso Train Score: %.3f'%lasso_train_score)\n",
    "# print('Lasso Test Score: %.3f'%lasso_test_score)\n",
    "# print('Number of Features Used: %d'%lasso_coeff_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, facecolor='w', figsize=(8, 14))\n",
    "\n",
    "# ranksort = np.argsort(abs(lasso.coef_))[::-1]\n",
    "# lasso_coefs = lasso.coef_[ranksort]\n",
    "# lasso_keys = X_train_norm.keys()[ranksort]\n",
    "# mask = lasso_coefs != 0\n",
    "\n",
    "# ax.axvline(0, color='k', linewidth=3, zorder=11)\n",
    "# ax.barh(lasso_keys[mask], lasso_coefs[mask], color='green', zorder=10, height=0.97)\n",
    "\n",
    "# for i, k in enumerate(lasso_keys[mask]):\n",
    "#     if lasso_coefs[i] != 0:\n",
    "#         ax.text(lasso_coefs[i]/2, k, k, zorder=20)\n",
    "\n",
    "# ax.invert_yaxis()\n",
    "# ax.axes.get_yaxis().set_visible(False)\n",
    "# ax.set_title('Lasso Regression Coefs')\n",
    "# ax.set_xlabel('Lasso Coef Value')\n",
    "# ax.grid(zorder=-1)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# # Grid-search for best parameters? (alpha and l1_ratio)\n",
    "\n",
    "# elastic = ElasticNet(alpha=0.009, l1_ratio=0.1, max_iter=10e5)\n",
    "# elastic.fit(X_train_norm, y_train)\n",
    "\n",
    "# elastic_train_score = elastic.score(X_train_norm, y_train)\n",
    "# elastic_test_score = elastic.score(X_test_norm, y_test)\n",
    "# elastic_coeff_used = np.sum(elastic.coef_ != 0)\n",
    "    \n",
    "# print('Elastic Train Score: %.3f'%elastic_train_score)\n",
    "# print('Elastic Test Score: %.3f'%elastic_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, facecolor='w', figsize=(8, 14))\n",
    "\n",
    "# ranksort = np.argsort(abs(elastic.coef_))[::-1]\n",
    "# elastic_coefs = elastic.coef_[ranksort]\n",
    "# elastic_keys = X_train_norm.keys()[ranksort]\n",
    "# mask = elastic_coefs != 0\n",
    "\n",
    "# ax.axvline(0, color='k', linewidth=3, zorder=11)\n",
    "# ax.barh(elastic_keys[mask], elastic_coefs[mask], color='green', zorder=10, height=0.97)\n",
    "\n",
    "# for i, k in enumerate(elastic_keys[mask]):\n",
    "#     if elastic_coefs[i] != 0:\n",
    "#         ax.text(elastic_coefs[i]/2, k, k, zorder=20)\n",
    "\n",
    "# ax.invert_yaxis()\n",
    "# ax.axes.get_yaxis().set_visible(False)\n",
    "# ax.set_title('Elastic Regression Coefs')\n",
    "# ax.set_xlabel('Elastic Coef Value')\n",
    "# ax.grid(zorder=-1)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we want to use feature selection, we can do so here.\n",
    "Can choose the model from which to take features, do so manually, or not at all (set equal to X_train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Top Predictor: %s'%elastic_keys[0])\n",
    "# fig, axs = plt.subplots(3, 3, figsize=(18, 18), facecolor='w')\n",
    "# axs = axs.flatten()\n",
    "\n",
    "# for i, ax in enumerate(axs):\n",
    "#     ik, ic = elastic_keys[i], elastic_coefs[i]\n",
    "#     ax.scatter(X_train_norm[ik], y_train, c='k', marker='+', s=65, linewidth=0.5)\n",
    "#     ax.set_title('(%d: %.2f) %s'%(i+1, ic, ik))\n",
    "#     ax.grid()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_low_import = False\n",
    "\n",
    "# if drop_low_import:\n",
    "#     feature_selection = elastic_keys[mask]\n",
    "#     feature_selection\n",
    "\n",
    "#     pre_select = X_train_norm.keys()\n",
    "#     X_train_norm = X_train_norm[feature_selection]\n",
    "#     X_test_norm = X_test_norm[feature_selection]\n",
    "#     post_select = X_train_norm.keys()\n",
    "\n",
    "#     print('dropped:', [k for k in pre_select if k not in post_select])\n",
    "\n",
    "#     print(X_train_norm.shape)\n",
    "#     print(X_test_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# for layer_sizes in [500]:\n",
    "#     mlp = MLPRegressor(\n",
    "#         hidden_layer_sizes=(layer_sizes,), \n",
    "#         activation='relu', \n",
    "#         solver='sgd', \n",
    "#         alpha=0.00001, \n",
    "#         batch_size='auto', \n",
    "#         learning_rate='adaptive', \n",
    "#         learning_rate_init=0.01, \n",
    "#         power_t=0.5, \n",
    "#         max_iter=50000, \n",
    "#         shuffle=True, \n",
    "#         random_state=random_state, \n",
    "#         tol=0.0001, \n",
    "#         verbose=False, \n",
    "#         warm_start=False, \n",
    "#         momentum=0.7, \n",
    "#         nesterovs_momentum=True, \n",
    "#         early_stopping=False, \n",
    "#         validation_fraction=0.3, \n",
    "#         beta_1=0.5, \n",
    "#         beta_2=0.999, \n",
    "#         epsilon=1e-8)\n",
    "\n",
    "#     mlp.fit(X_train_norm, y_train)\n",
    "\n",
    "#     mlp_train_score = mlp.score(X_train_norm, y_train)\n",
    "#     mlp_test_score = mlp.score(X_test_norm, y_test)\n",
    "    \n",
    "#     # mlp_coeff_used = np.sum(mlp.coef_ != 0)\n",
    "\n",
    "#     print('Layer Sizes: %d'%layer_sizes)\n",
    "#     print('MLP Train Score: %.3f'%mlp_train_score)\n",
    "#     print('MLP Test Score: %.3f'%mlp_test_score)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = mlp.predict(X_test_norm)\n",
    "# mlp_mae = np.nanmean(abs(test_predictions - y_test))\n",
    "\n",
    "# maxslr = test_predictions.max() if test_predictions.max() > y_test.max() else y_test.max()\n",
    "# maxslr += 5\n",
    "\n",
    "# fig, axs = plt.subplots(1, 3, figsize=(30, 8), facecolor='w')\n",
    "\n",
    "# ax = axs[0]\n",
    "# maxslr = y_test.max() if y_test.max() > y_train.max() else y_train.max()\n",
    "\n",
    "# ax.hist(y_train, bins=np.arange(0, maxslr, 2), color='g', edgecolor='k', alpha=1.0, label='Train SLR\\nn=%d'%len(y_train))\n",
    "# ax.hist(y_test, bins=np.arange(0, maxslr, 2), color='C0', edgecolor='k', alpha=1.0, label='Test SLR\\nn=%d'%len(y_test))\n",
    "# ax.legend()\n",
    "\n",
    "# ax.set_xticks(np.arange(0, maxslr+1, 5))\n",
    "# ax.set_xticklabels(np.arange(0, maxslr+1, 5).astype(int))\n",
    "# ax.grid()\n",
    "\n",
    "# ax = axs[1]\n",
    "# maxslr = test_predictions.max() if test_predictions.max() > y_test.max() else y_test.max()\n",
    "# maxslr += 5\n",
    "# ax.scatter(y_test, test_predictions, c='k', s=50, marker='+', linewidth=0.75)\n",
    "# ax.set_xlabel('Observed SLR')\n",
    "# ax.set_ylabel('Predicted SLR')\n",
    "# ax.plot([0, maxslr], [0, maxslr])\n",
    "# ax.set_xlim([0, maxslr])\n",
    "# ax.set_ylim([0, maxslr])\n",
    "# ax.set_aspect('equal')\n",
    "# ax.grid()\n",
    "# axs[1].set_title('R2: %.3f\\nMAE: %.3f'%(mlp_test_score, mlp_mae))\n",
    "\n",
    "# ax = axs[2]\n",
    "# error = test_predictions - y_test\n",
    "# ax.hist(error, bins=np.arange(-30, 30, 2), edgecolor='k')\n",
    "# ax.set_xlabel('Prediction Error')\n",
    "# ax.set_ylabel('Count')\n",
    "# ax.grid()\n",
    "\n",
    "# fig.suptitle('MultiLayer Perceptron (Simple ANN) [%d Hidden Layer Sizes]'%layer_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Support Vector Regression Model\n",
    "(Other ML models like ANN from keras, tensorflow, pytorch may be used in this block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a K-Fold Cross Validation to assess model performance (Optional, recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the SVR model multiprocess friendly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MARE(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "def SVR_mp(_params):\n",
    "    \n",
    "    print('.', end='')\n",
    "    \n",
    "    _i, _j, _C, _e = _params\n",
    "    \n",
    "    _model = SVR(\n",
    "                C=_C, #Ridge regularization parameter for (L2)^2 penalty\n",
    "                epsilon=_e, #Specifies the epsilon-tube within which no penalty is associated in the training loss function\n",
    "                kernel='rbf', #'linear', 'polynomial', 'rbf'\n",
    "                degree=3, #pass interger for 'polynomial' kernel, ignored otherwise\n",
    "                tol=0.001, #stopping tolerance\n",
    "                shrinking=False, \n",
    "                cache_size=200, \n",
    "                verbose=False)\n",
    "    \n",
    "    _model.fit(X_train_norm, y_train)\n",
    "    \n",
    "    test_predictions = _model.predict(X_test_norm).flatten()\n",
    "    _r2 = _model.score(X_test_norm, y_test) #sklearn.metrics.r2_score(y_test.values.flatten(), test_predictions)\n",
    "    _mse = sklearn.metrics.mean_squared_error(y_test.values.flatten(), test_predictions)\n",
    "    _mae = sklearn.metrics.mean_absolute_error(y_test.values.flatten(), test_predictions)\n",
    "    _mare = MARE(y_test.values.flatten(), test_predictions)\n",
    "    \n",
    "    return (_i, _j, _C, _e, _r2, _mae, _mse, _mare, _model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations to attempt: 56\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from sklearn.svm import SVR\n",
    "import sklearn\n",
    "\n",
    "# Best test\n",
    "crange = np.arange(80, 120, 5)\n",
    "erange = np.arange(1.0, 4.1, .5)\n",
    "\n",
    "# crange = np.arange(1, 25, 1)\n",
    "# erange = np.arange(0.1, 3.1, .1)\n",
    "\n",
    "params = {}\n",
    "params['r2'] = np.zeros((len(crange), len(erange)))\n",
    "params['mae'] = np.zeros((len(crange), len(erange)))\n",
    "params['mse'] = np.zeros((len(crange), len(erange)))\n",
    "params['mare'] = np.zeros((len(crange), len(erange)))\n",
    "params['model'] = np.empty((len(crange), len(erange)), dtype='object')\n",
    "params['epsilon'] = np.zeros((len(crange), len(erange)))\n",
    "params['C'] = np.zeros((len(crange), len(erange)))\n",
    "\n",
    "mp_params = np.array([[(i, j, C, e) for j, e in enumerate(erange)] \n",
    "                      for i, C in enumerate(crange)]).reshape(-1, 4)\n",
    "\n",
    "print('Iterations to attempt: %d'%len(mp_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run SVR, collect output iterated over hyperparameters (C, epsilon)<br>\n",
    "Specify the cost function/loss function used, tolerances, kernel, error metric, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/uufs/chpc.utah.edu/common/home/u1070830/anaconda3/envs/xlab/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-26-e48cf210ad3d>\", line 5, in <module>\n",
      "    mp_returns = p.map(SVR_mp, mp_params, chunksize=1)\n",
      "  File \"/uufs/chpc.utah.edu/common/home/u1070830/anaconda3/envs/xlab/lib/python3.8/multiprocessing/pool.py\", line 364, in map\n",
      "    return self._map_async(func, iterable, mapstar, chunksize).get()\n",
      "  File \"/uufs/chpc.utah.edu/common/home/u1070830/anaconda3/envs/xlab/lib/python3.8/multiprocessing/pool.py\", line 765, in get\n",
      "    self.wait(timeout)\n",
      "  File \"/uufs/chpc.utah.edu/common/home/u1070830/anaconda3/envs/xlab/lib/python3.8/multiprocessing/pool.py\", line 762, in wait\n",
      "    self._event.wait(timeout)\n",
      "  File \"/uufs/chpc.utah.edu/common/home/u1070830/anaconda3/envs/xlab/lib/python3.8/threading.py\", line 558, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/uufs/chpc.utah.edu/common/home/u1070830/anaconda3/envs/xlab/lib/python3.8/threading.py\", line 302, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/uufs/chpc.utah.edu/common/home/u1070830/anaconda3/envs/xlab/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/uufs/chpc.utah.edu/common/home/u1070830/anaconda3/envs/xlab/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/uufs/chpc.utah.edu/common/home/u1070830/anaconda3/envs/xlab/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/uufs/chpc.utah.edu/common/home/u1070830/anaconda3/envs/xlab/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/uufs/chpc.utah.edu/common/home/u1070830/anaconda3/envs/xlab/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/uufs/chpc.utah.edu/common/home/u1070830/anaconda3/envs/xlab/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/uufs/chpc.utah.edu/common/home/u1070830/anaconda3/envs/xlab/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/uufs/chpc.utah.edu/common/home/u1070830/anaconda3/envs/xlab/lib/python3.8/inspect.py\", line 753, in getmodule\n",
      "    modulesbyfile[f] = modulesbyfile[\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-e48cf210ad3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fork'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmp_returns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVR_mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmp_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xlab/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    363\u001b[0m         '''\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xlab/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xlab/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xlab/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xlab/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/xlab/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xlab/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2044\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2046\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2047\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xlab/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1433\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1435\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1436\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xlab/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1336\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/xlab/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1193\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xlab/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xlab/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# Paralellize here\n",
    "# mp_returns = [SVR_mp(_param) for _param in mp_params[:10]]\n",
    "\n",
    "with mp.get_context('fork').Pool(64) as p:\n",
    "    mp_returns = p.map(SVR_mp, mp_params, chunksize=1)\n",
    "    p.close()\n",
    "    p.join()\n",
    "\n",
    "for item in mp_returns:\n",
    "    \n",
    "    i, j, C, e, r2, mae, mse, mare, model = item\n",
    "    i, j = int(i), int(j)\n",
    "        \n",
    "    params['r2'][i, j] = r2\n",
    "    params['mse'][i, j] = mse\n",
    "    params['mae'][i, j] = mae\n",
    "    params['mare'][i, j] = mare\n",
    "    params['model'][i, j] = model\n",
    "    params['epsilon'][i, j] = e\n",
    "    params['C'][i, j] = C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot model performance over time, cost/loss function evolution and skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>swe_mm</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>Q_01agl</th>\n",
       "      <th>T_01agl</th>\n",
       "      <th>U_01agl</th>\n",
       "      <th>V_01agl</th>\n",
       "      <th>VO_01agl</th>\n",
       "      <th>W_01agl</th>\n",
       "      <th>Z_01agl</th>\n",
       "      <th>R_01agl</th>\n",
       "      <th>...</th>\n",
       "      <th>CAPE</th>\n",
       "      <th>MSL</th>\n",
       "      <th>U10M</th>\n",
       "      <th>V10M</th>\n",
       "      <th>U100M</th>\n",
       "      <th>V100M</th>\n",
       "      <th>SPD10M</th>\n",
       "      <th>DIR10M</th>\n",
       "      <th>SPD100M</th>\n",
       "      <th>DIR100M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.687449</td>\n",
       "      <td>-0.096085</td>\n",
       "      <td>-0.353995</td>\n",
       "      <td>0.309195</td>\n",
       "      <td>-1.482530</td>\n",
       "      <td>-0.014897</td>\n",
       "      <td>-1.389487</td>\n",
       "      <td>1.358642</td>\n",
       "      <td>-5.255091</td>\n",
       "      <td>-1.104738</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.328069</td>\n",
       "      <td>-0.720391</td>\n",
       "      <td>-0.844162</td>\n",
       "      <td>-0.461278</td>\n",
       "      <td>-1.007397</td>\n",
       "      <td>-0.460140</td>\n",
       "      <td>-0.015270</td>\n",
       "      <td>-0.759608</td>\n",
       "      <td>-0.348842</td>\n",
       "      <td>-1.067009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.917145</td>\n",
       "      <td>0.224199</td>\n",
       "      <td>1.575769</td>\n",
       "      <td>0.685142</td>\n",
       "      <td>-1.020112</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>1.123717</td>\n",
       "      <td>0.491092</td>\n",
       "      <td>-0.552018</td>\n",
       "      <td>0.455238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991218</td>\n",
       "      <td>-1.470192</td>\n",
       "      <td>0.687112</td>\n",
       "      <td>-1.491316</td>\n",
       "      <td>0.327587</td>\n",
       "      <td>-1.303397</td>\n",
       "      <td>0.009318</td>\n",
       "      <td>1.508969</td>\n",
       "      <td>-0.203390</td>\n",
       "      <td>0.776383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.479081</td>\n",
       "      <td>0.932384</td>\n",
       "      <td>0.308695</td>\n",
       "      <td>0.975874</td>\n",
       "      <td>-0.734851</td>\n",
       "      <td>1.071337</td>\n",
       "      <td>-4.382256</td>\n",
       "      <td>0.872565</td>\n",
       "      <td>-5.493533</td>\n",
       "      <td>-0.827968</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.282355</td>\n",
       "      <td>-1.304430</td>\n",
       "      <td>-0.947680</td>\n",
       "      <td>1.080872</td>\n",
       "      <td>-1.234842</td>\n",
       "      <td>1.212084</td>\n",
       "      <td>1.162876</td>\n",
       "      <td>-0.389855</td>\n",
       "      <td>1.428461</td>\n",
       "      <td>-0.549593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.062346</td>\n",
       "      <td>-0.263345</td>\n",
       "      <td>-1.256848</td>\n",
       "      <td>-2.426643</td>\n",
       "      <td>0.383254</td>\n",
       "      <td>-0.572824</td>\n",
       "      <td>0.427992</td>\n",
       "      <td>-1.404318</td>\n",
       "      <td>-0.665700</td>\n",
       "      <td>0.804228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213168</td>\n",
       "      <td>0.428299</td>\n",
       "      <td>0.859384</td>\n",
       "      <td>-0.209206</td>\n",
       "      <td>0.803110</td>\n",
       "      <td>-0.402515</td>\n",
       "      <td>-0.567897</td>\n",
       "      <td>0.795944</td>\n",
       "      <td>-0.449398</td>\n",
       "      <td>0.774993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.166530</td>\n",
       "      <td>-0.231317</td>\n",
       "      <td>0.083303</td>\n",
       "      <td>0.384019</td>\n",
       "      <td>-1.318799</td>\n",
       "      <td>0.736113</td>\n",
       "      <td>-4.226767</td>\n",
       "      <td>1.693443</td>\n",
       "      <td>-6.029549</td>\n",
       "      <td>-0.634186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.223570</td>\n",
       "      <td>-1.816715</td>\n",
       "      <td>-0.737354</td>\n",
       "      <td>0.648263</td>\n",
       "      <td>-1.219117</td>\n",
       "      <td>0.639424</td>\n",
       "      <td>0.542839</td>\n",
       "      <td>-0.438784</td>\n",
       "      <td>0.750839</td>\n",
       "      <td>-0.672281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7227</th>\n",
       "      <td>0.666940</td>\n",
       "      <td>-0.131673</td>\n",
       "      <td>-0.919830</td>\n",
       "      <td>-1.336659</td>\n",
       "      <td>-0.041977</td>\n",
       "      <td>0.991985</td>\n",
       "      <td>-0.718531</td>\n",
       "      <td>-0.388673</td>\n",
       "      <td>-0.554805</td>\n",
       "      <td>-0.040792</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225036</td>\n",
       "      <td>-0.088817</td>\n",
       "      <td>-0.091907</td>\n",
       "      <td>0.686700</td>\n",
       "      <td>-0.289815</td>\n",
       "      <td>0.656582</td>\n",
       "      <td>0.820740</td>\n",
       "      <td>0.038107</td>\n",
       "      <td>0.898605</td>\n",
       "      <td>-0.169922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7228</th>\n",
       "      <td>-0.270714</td>\n",
       "      <td>-0.014235</td>\n",
       "      <td>0.781719</td>\n",
       "      <td>0.499388</td>\n",
       "      <td>0.642249</td>\n",
       "      <td>0.251710</td>\n",
       "      <td>0.266507</td>\n",
       "      <td>-0.696841</td>\n",
       "      <td>0.645172</td>\n",
       "      <td>-0.117018</td>\n",
       "      <td>...</td>\n",
       "      <td>8.974205</td>\n",
       "      <td>-0.030439</td>\n",
       "      <td>0.389384</td>\n",
       "      <td>-0.436198</td>\n",
       "      <td>0.284538</td>\n",
       "      <td>-0.215158</td>\n",
       "      <td>0.055551</td>\n",
       "      <td>0.463530</td>\n",
       "      <td>-0.086894</td>\n",
       "      <td>0.418112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7229</th>\n",
       "      <td>-0.166530</td>\n",
       "      <td>0.953737</td>\n",
       "      <td>-0.189131</td>\n",
       "      <td>-0.470386</td>\n",
       "      <td>-0.019589</td>\n",
       "      <td>-0.797980</td>\n",
       "      <td>0.283131</td>\n",
       "      <td>0.968280</td>\n",
       "      <td>-0.382237</td>\n",
       "      <td>0.068170</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033037</td>\n",
       "      <td>-0.460619</td>\n",
       "      <td>-0.073414</td>\n",
       "      <td>-1.077116</td>\n",
       "      <td>-0.337346</td>\n",
       "      <td>-1.081369</td>\n",
       "      <td>-0.484781</td>\n",
       "      <td>-0.337103</td>\n",
       "      <td>-0.448006</td>\n",
       "      <td>-1.061623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7230</th>\n",
       "      <td>-0.187039</td>\n",
       "      <td>-0.124555</td>\n",
       "      <td>0.231512</td>\n",
       "      <td>-0.384542</td>\n",
       "      <td>0.467180</td>\n",
       "      <td>0.143275</td>\n",
       "      <td>0.876215</td>\n",
       "      <td>-0.553589</td>\n",
       "      <td>0.545230</td>\n",
       "      <td>0.593041</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057589</td>\n",
       "      <td>0.655100</td>\n",
       "      <td>-0.042347</td>\n",
       "      <td>0.769367</td>\n",
       "      <td>-0.167695</td>\n",
       "      <td>0.716582</td>\n",
       "      <td>0.208874</td>\n",
       "      <td>-0.065273</td>\n",
       "      <td>0.402673</td>\n",
       "      <td>-0.212220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7231</th>\n",
       "      <td>0.250205</td>\n",
       "      <td>0.935943</td>\n",
       "      <td>-0.658187</td>\n",
       "      <td>-1.041881</td>\n",
       "      <td>0.290042</td>\n",
       "      <td>-0.138813</td>\n",
       "      <td>0.516466</td>\n",
       "      <td>-0.556099</td>\n",
       "      <td>-1.148467</td>\n",
       "      <td>-0.130008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831725</td>\n",
       "      <td>-1.278146</td>\n",
       "      <td>0.514506</td>\n",
       "      <td>-0.399206</td>\n",
       "      <td>0.520334</td>\n",
       "      <td>-0.282577</td>\n",
       "      <td>0.132599</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>0.282407</td>\n",
       "      <td>0.912030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7232 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        swe_mm  day_of_year   Q_01agl   T_01agl   U_01agl   V_01agl  VO_01agl  \\\n",
       "0    -0.687449    -0.096085 -0.353995  0.309195 -1.482530 -0.014897 -1.389487   \n",
       "1     0.917145     0.224199  1.575769  0.685142 -1.020112  0.088889  1.123717   \n",
       "2    -0.479081     0.932384  0.308695  0.975874 -0.734851  1.071337 -4.382256   \n",
       "3    -0.062346    -0.263345 -1.256848 -2.426643  0.383254 -0.572824  0.427992   \n",
       "4    -0.166530    -0.231317  0.083303  0.384019 -1.318799  0.736113 -4.226767   \n",
       "...        ...          ...       ...       ...       ...       ...       ...   \n",
       "7227  0.666940    -0.131673 -0.919830 -1.336659 -0.041977  0.991985 -0.718531   \n",
       "7228 -0.270714    -0.014235  0.781719  0.499388  0.642249  0.251710  0.266507   \n",
       "7229 -0.166530     0.953737 -0.189131 -0.470386 -0.019589 -0.797980  0.283131   \n",
       "7230 -0.187039    -0.124555  0.231512 -0.384542  0.467180  0.143275  0.876215   \n",
       "7231  0.250205     0.935943 -0.658187 -1.041881  0.290042 -0.138813  0.516466   \n",
       "\n",
       "       W_01agl   Z_01agl   R_01agl  ...      CAPE       MSL      U10M  \\\n",
       "0     1.358642 -5.255091 -1.104738  ... -0.328069 -0.720391 -0.844162   \n",
       "1     0.491092 -0.552018  0.455238  ...  0.991218 -1.470192  0.687112   \n",
       "2     0.872565 -5.493533 -0.827968  ... -0.282355 -1.304430 -0.947680   \n",
       "3    -1.404318 -0.665700  0.804228  ...  0.213168  0.428299  0.859384   \n",
       "4     1.693443 -6.029549 -0.634186  ... -0.223570 -1.816715 -0.737354   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7227 -0.388673 -0.554805 -0.040792  ... -0.225036 -0.088817 -0.091907   \n",
       "7228 -0.696841  0.645172 -0.117018  ...  8.974205 -0.030439  0.389384   \n",
       "7229  0.968280 -0.382237  0.068170  ... -0.033037 -0.460619 -0.073414   \n",
       "7230 -0.553589  0.545230  0.593041  ... -0.057589  0.655100 -0.042347   \n",
       "7231 -0.556099 -1.148467 -0.130008  ...  0.831725 -1.278146  0.514506   \n",
       "\n",
       "          V10M     U100M     V100M    SPD10M    DIR10M   SPD100M   DIR100M  \n",
       "0    -0.461278 -1.007397 -0.460140 -0.015270 -0.759608 -0.348842 -1.067009  \n",
       "1    -1.491316  0.327587 -1.303397  0.009318  1.508969 -0.203390  0.776383  \n",
       "2     1.080872 -1.234842  1.212084  1.162876 -0.389855  1.428461 -0.549593  \n",
       "3    -0.209206  0.803110 -0.402515 -0.567897  0.795944 -0.449398  0.774993  \n",
       "4     0.648263 -1.219117  0.639424  0.542839 -0.438784  0.750839 -0.672281  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "7227  0.686700 -0.289815  0.656582  0.820740  0.038107  0.898605 -0.169922  \n",
       "7228 -0.436198  0.284538 -0.215158  0.055551  0.463530 -0.086894  0.418112  \n",
       "7229 -1.077116 -0.337346 -1.081369 -0.484781 -0.337103 -0.448006 -1.061623  \n",
       "7230  0.769367 -0.167695  0.716582  0.208874 -0.065273  0.402673 -0.212220  \n",
       "7231 -0.399206  0.520334 -0.282577  0.132599  0.668023  0.282407  0.912030  \n",
       "\n",
       "[7232 rows x 105 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot SVR output with hyperparameters (C, epsilon)<br>\n",
    "Apply a grid-search method to select best performing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_on, indexer, _ = 'R2', np.where(params['r2'] == params['r2'].max()), params['r2'].max()\n",
    "min_on, indexer, _ = 'MAE', np.where(params['mae'] == params['mae'].min()), params['mae'].min()\n",
    "min_on, indexer, _ = 'MSE', np.where(params['mse'] == params['mse'].min()), params['mse'].min()\n",
    "min_on, indexer, _ = 'MARE', np.where(params['mare'] == params['mare'].min()), params['mare'].min()\n",
    "\n",
    "for min_on in ['r2']:\n",
    "    \n",
    "    if min_on in ['mse', 'mae', 'mare']:\n",
    "        min_max = 'Minimized'\n",
    "        indexer = np.where(params[min_on] == params[min_on].min())\n",
    "    elif min_on in ['r2']:\n",
    "        min_max = 'Maximized'\n",
    "        indexer = np.where(params[min_on] == params[min_on].max())\n",
    "\n",
    "    r, c = indexer\n",
    "    r, c = r[0], c[0]\n",
    "    r, c, _\n",
    "\n",
    "    model = params['model'][r, c]\n",
    "    test_predictions = model.predict(X_test_norm)\n",
    "    \n",
    "    y_true = y_test\n",
    "    y_pred = test_predictions\n",
    "    print('MARE ', MARE(y_true, y_pred))\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, facecolor='w', figsize=(24, 14))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    ax = axs[0]\n",
    "    cbar = ax.pcolormesh(erange, crange, params['mae'])\n",
    "    plt.colorbar(cbar, label='mae', ax=ax)\n",
    "    ax.set_title('Min MAE: %.3f'%params['mae'][r, c])\n",
    "    ax.scatter(params['epsilon'][r, c], params['C'][r, c], s=500, c='w', marker='+')\n",
    "\n",
    "    ax = axs[1]\n",
    "    cbar = ax.pcolormesh(erange, crange, params['mse'])\n",
    "    plt.colorbar(cbar, label='mse', ax=ax)\n",
    "    ax.set_title('Min MSE: %.3f'%params['mse'][r, c])\n",
    "    ax.scatter(params['epsilon'][r, c], params['C'][r, c], s=500, c='w', marker='+')\n",
    "\n",
    "    ax = axs[2]\n",
    "    cbar = ax.pcolormesh(erange, crange, params['r2'])\n",
    "    plt.colorbar(cbar, label='r2', ax=ax)\n",
    "    ax.set_title('Max R^2: %.3f'%params['r2'][r, c])\n",
    "    ax.scatter(params['epsilon'][r, c], params['C'][r, c], s=500, c='k', marker='+')\n",
    "\n",
    "    for ax in axs[:3]:\n",
    "        ax.set_xlabel('epsilon')\n",
    "        ax.set_ylabel('C_val')\n",
    "        ax.set_ylim([crange.min(), crange.max()])\n",
    "        ax.set_xlim([erange.min(), erange.max()])\n",
    "\n",
    "    ax = axs[3]\n",
    "    maxslr = y_test.max() if y_test.max() > y_train.max() else y_train.max()\n",
    "\n",
    "    ax.hist(y_train, bins=np.arange(0, maxslr, 2), color='g', edgecolor='k', alpha=1.0, label='Train SLR\\nn=%d'%len(y_train))\n",
    "    ax.hist(y_test, bins=np.arange(0, maxslr, 2), color='C0', edgecolor='k', alpha=1.0, label='Test SLR\\nn=%d'%len(y_test))\n",
    "    ax.legend()\n",
    "\n",
    "    ax.set_xticks(np.arange(0, maxslr+1, 5))\n",
    "    ax.set_xticklabels(np.arange(0, maxslr+1, 5).astype(int))\n",
    "    ax.grid()\n",
    "\n",
    "    ax = axs[4]\n",
    "    maxslr = test_predictions.max() if test_predictions.max() > y_test.max() else y_test.max()\n",
    "    maxslr += 5\n",
    "    ax.scatter(y_test, test_predictions, c='k', s=50, marker='+', linewidth=0.75)\n",
    "    ax.set_xlabel('Observed SLR')\n",
    "    ax.set_ylabel('Predicted SLR')\n",
    "    ax.plot([0, maxslr], [0, maxslr])\n",
    "    ax.set_xlim([0, maxslr])\n",
    "    ax.set_ylim([0, maxslr])\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid()\n",
    "\n",
    "    ax = axs[5]\n",
    "    error = test_predictions - y_test\n",
    "    ax.hist(error, bins=np.arange(-30, 30, 2), edgecolor='k')\n",
    "    ax.set_xlabel('Prediction Error')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.grid()\n",
    "\n",
    "    plt.suptitle('Support Vector Regression Model\\n%s\\n%s on: %s\\n\\nepsilon %.3f\\nc_val: %.3f'%(site_list, min_max, min_on.upper(), params['epsilon'][r, c], params['C'][r, c]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe final trained SVR model\n",
    "Descriptive plots of predictor coefficient rank/influence<br>\n",
    "Print out model parameters, error metrics, skill scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranksort = np.argsort(abs(model.coef_))[::-1]\n",
    "# svr_coefs = model.coef_[0][ranksort][0]\n",
    "# svr_keys = X_train_norm.keys()[ranksort][0]\n",
    "# mask = svr_coefs != 0\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, facecolor='w', figsize=(8, 14))\n",
    "\n",
    "# ax.axvline(0, color='k', linewidth=3, zorder=11)\n",
    "# ax.barh(svr_keys[mask], svr_coefs[mask], color='green', zorder=10, height=0.97)\n",
    "\n",
    "# for i, k in enumerate(svr_keys):\n",
    "#     if svr_coefs[i] != 0:\n",
    "#         ax.text(svr_coefs[i]/2, k, k, zorder=20)\n",
    "\n",
    "# # ax.invert_yaxis()\n",
    "# ax.axes.get_yaxis().set_visible(False)\n",
    "# ax.set_title('SVR Coefs')\n",
    "# ax.set_xlabel('SVR Coef Value')\n",
    "# ax.grid(zorder=-1)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save out a usable model along with the input parameters for application\n",
    "Save with a descriptive filename and a metadata text file!<br>\n",
    "This will make swapping out models for evaluation much simpler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
